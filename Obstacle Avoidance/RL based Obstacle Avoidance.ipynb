{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxgc8v3E3gDBM0E5xTpqE4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-EGK/Intelligent-Path-Planning/blob/main/Obstacle%20Avoidance/RL%20based%20Obstacle%20Avoidance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oARZLkrGwL0N"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Global Variables\n",
        "BOARD_ROWS = 10\n",
        "BOARD_COLS = 10\n",
        "WIN_STATE = (9,9)\n",
        "START = (0,0)\n",
        "DETERMINISTIC = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1_HF5TKRBd8"
      },
      "source": [
        "class State:\n",
        "    def __init__(self, state=START):\n",
        "        self.board = np.zeros([BOARD_ROWS, BOARD_COLS])\n",
        "        self.board[1, 5] = -1\n",
        "        self.board[1, 7] = -1\n",
        "        self.board[3, 2] = -1\n",
        "        self.board[3, 4] = -1\n",
        "        self.board[3, 8] = -1\n",
        "        self.board[4, 2] = -1\n",
        "        self.board[4, 8] = -1\n",
        "        self.board[6, 3] = -1\n",
        "        self.board[6, 5] = -1\n",
        "        self.board[8, 7] = -1\n",
        "        self.state = state\n",
        "        self.isEnd = False\n",
        "        self.determine = DETERMINISTIC\n",
        "\n",
        "    def giveReward(self):\n",
        "        if self.state == WIN_STATE:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def isEndFunc(self):\n",
        "        if (self.state == WIN_STATE):\n",
        "            self.isEnd = True\n",
        "\n",
        "    def nxtPosition(self, action):\n",
        "        if self.determine:\n",
        "            if action == \"up\":\n",
        "                nxtState = (self.state[0] - 1, self.state[1])\n",
        "            elif action == \"down\":\n",
        "                nxtState = (self.state[0] + 1, self.state[1])\n",
        "            elif action == \"left\":\n",
        "                nxtState = (self.state[0], self.state[1] - 1)\n",
        "            else:\n",
        "                nxtState = (self.state[0], self.state[1] + 1)\n",
        "            # if next state legal\n",
        "            if (nxtState[0] >= 0) and (nxtState[0] <= (BOARD_ROWS -1)):\n",
        "                if (nxtState[1] >= 0) and (nxtState[1] <= (BOARD_COLS -1)):\n",
        "                    if nxtState != (1, 5) and nxtState != (1, 7) and nxtState != (3, 2) and nxtState != (3, 4) and nxtState != (3, 8) and nxtState != (4, 2) and nxtState != (4, 8) and nxtState != (6, 3) and nxtState != (6, 5) and nxtState != (8, 7):\n",
        "                        return nxtState\n",
        "            return self.state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVG7Cz2WS1nm"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.states = []\n",
        "        self.actions = [\"up\", \"down\", \"left\", \"right\"]\n",
        "        self.State = State()\n",
        "        self.lr = 0.2\n",
        "        self.exp_rate = 0.5\n",
        "\n",
        "        # initial state reward\n",
        "        self.state_values = {}\n",
        "        for i in range(BOARD_ROWS):\n",
        "            for j in range(BOARD_COLS):\n",
        "                self.state_values[(i, j)] = 0  # set initial value to 0\n",
        "        self.state_values[(1, 5)] = -1\n",
        "        self.state_values[(1, 7)] = -1\n",
        "        self.state_values[(3, 2)] = -1\n",
        "        self.state_values[(3, 4)] = -1\n",
        "        self.state_values[(3, 8)] = -1\n",
        "        self.state_values[(4, 2)] = -1\n",
        "        self.state_values[(4, 8)] = -1\n",
        "        self.state_values[(6, 3)] = -1\n",
        "        self.state_values[(6, 5)] = -1\n",
        "        self.state_values[(8, 7)] = -1\n",
        "\n",
        "    def chooseAction(self):\n",
        "        # choose action with most expected value\n",
        "        mx_nxt_reward = 0\n",
        "        action = \"\"\n",
        "\n",
        "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
        "            action = np.random.choice(self.actions)\n",
        "        else:\n",
        "            # greedy action\n",
        "            for a in self.actions:\n",
        "                # if the action is deterministic\n",
        "                nxt_reward = self.state_values[self.State.nxtPosition(a)]\n",
        "                if nxt_reward >= mx_nxt_reward:\n",
        "                    action = a\n",
        "                    mx_nxt_reward = nxt_reward\n",
        "        return action\n",
        "\n",
        "    def takeAction(self, action):\n",
        "        position = self.State.nxtPosition(action)\n",
        "        return State(state=position)\n",
        "\n",
        "    def reset(self):\n",
        "        self.states = []\n",
        "        self.State = State()\n",
        "\n",
        "    def play(self, rounds=10):\n",
        "        i = 0\n",
        "        while i < rounds:\n",
        "            # to the end of game back propagate reward\n",
        "            if self.State.isEnd:\n",
        "                # back propagate\n",
        "                reward = self.State.giveReward()\n",
        "                # explicitly assign end state to reward values\n",
        "                self.state_values[self.State.state] = reward  # this is optional\n",
        "                # print(\"Game End Reward\", reward)\n",
        "                # print(\"***********************\")\n",
        "                for s in reversed(self.states):\n",
        "                    reward = self.state_values[s] + self.lr * (reward - self.state_values[s])\n",
        "                    self.state_values[s] = round(reward, 3)\n",
        "                self.reset()\n",
        "                i += 1\n",
        "            else:\n",
        "                action = self.chooseAction()\n",
        "                # append trace\n",
        "                self.states.append(self.State.nxtPosition(action))\n",
        "                # print(\"current position {} action {}\".format(self.State.state, action))\n",
        "                # by taking the action, it reaches the next state\n",
        "                self.State = self.takeAction(action)\n",
        "                # mark is end\n",
        "                self.State.isEndFunc()\n",
        "                # print(\"nxt state\", self.State.state)\n",
        "                # print(\"---------------------\")\n",
        "\n",
        "    def showValues(self):\n",
        "        for i in range(0, BOARD_ROWS):\n",
        "            print('-------------------------------------------------------------------------------------------')\n",
        "            out = '| '\n",
        "            for j in range(0, BOARD_COLS):\n",
        "                out += str(self.state_values[(i, j)]).ljust(6) + ' | '\n",
        "            print(out)\n",
        "        print('-------------------------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrVr8h_SpO0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "160bda55-09aa-4f84-ada3-e028e0410230"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ag = Agent()\n",
        "    ag.play(100)\n",
        "    print(ag.showValues())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------------------------\n",
            "| 0.213  | 0.256  | 0.305  | 0.337  | 0.295  | 0.226  | 0.212  | 0.242  | 0.357  | 0.486  | \n",
            "-------------------------------------------------------------------------------------------\n",
            "| 0.057  | 0.206  | 0.301  | 0.383  | 0.43   | -1     | 0.509  | -1     | 0.668  | 0.721  | \n",
            "-------------------------------------------------------------------------------------------\n",
            "| 0.0    | 0.017  | 0.139  | 0.381  | 0.485  | 0.514  | 0.599  | 0.666  | 0.762  | 0.796  | \n",
            "-------------------------------------------------------------------------------------------\n",
            "| 0.001  | 0.004  | -1     | 0.165  | -1     | 0.452  | 0.547  | 0.584  | -1     | 0.845  | \n",
            "-------------------------------------------------------------------------------------------\n",
            "| 0      | 0      | -1     | 0.012  | 0      | 0.132  | 0.119  | 0.166  | -1     | 0.853  | \n",
            "-------------------------------------------------------------------------------------------\n",
            "| 0      | 0      | 0      | 0      | 0      | 0      | 0.025  | 0.14   | 0.608  | 0.901  | \n",
            "-------------------------------------------------------------------------------------------\n",
            "| 0      | 0      | 0      | -1     | 0      | -1     | 0.127  | 0.57   | 0.823  | 0.923  | \n",
            "-------------------------------------------------------------------------------------------\n",
            "| 0      | 0      | 0      | 0      | 0      | 0      | 0.134  | 0.432  | 0.919  | 0.958  | \n",
            "-------------------------------------------------------------------------------------------\n",
            "| 0      | 0      | 0      | 0      | 0      | 0      | 0.014  | -1     | 0.912  | 0.969  | \n",
            "-------------------------------------------------------------------------------------------\n",
            "| 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0.36   | 1.0    | \n",
            "-------------------------------------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}